{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outbrain Click Prediction solution\n",
    "\n",
    "(Please refer to OutbrainInitial and FeatureAnalysis for initial analysis and feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import gc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Toggle based on hardware - if low memory laptop set to True else False\n",
    "poor = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_meta = pd.read_csv('./data/documents_meta.csv',  dtype={\"document_id\": int, \"source_id\": object, \"publisher_id\": object, \"publish_time\": object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Add document ids for source and target documents\n",
    "def add_documents_ids(clicks):\n",
    "    events_df = pd.read_csv('./data/events.csv',  dtype={\"display_id\": int, \"uuid\": str, \"document_id\": int, \"timestamp\": int, \"platform\": str, \"geo_location\": str})\n",
    "    events_df = events_df[events_df.platform != '\\\\N']\n",
    "    events_df.platform = events_df.platform.astype(int)\n",
    "    clicks    = pd.merge(clicks, events_df, on='display_id')\n",
    "    del(events_df) # save memory\n",
    "    ## Add target doucment id info from promoted content\n",
    "    clicks = clicks.rename(index=str, columns={\"document_id\": \"source_document_id\"})\n",
    "    promoted_content = pd.read_csv('./data/promoted_content.csv',  dtype={\"ad_id\": int, \"document_id\": int, \"campaign_id\": object, \"advertiser_id\": object})\n",
    "    clicks = pd.merge(clicks, promoted_content, on='ad_id')\n",
    "    del(promoted_content)\n",
    "    return cleanup(clicks)\n",
    "\n",
    "## Add the regularized CTR calculated earlier\n",
    "def add_reg_ctr(clicks):\n",
    "    reg_ctr = pd.read_csv('./reg_ctr.csv',dtype={\"ad_id\":int, \"reg_ctr\":float})\n",
    "    clicks = pd.merge(clicks, reg_ctr, how = 'left', on = 'ad_id')\n",
    "    clicks['reg_ctr'].fillna(0, inplace=True)\n",
    "    del(reg_ctr)\n",
    "    return clicks\n",
    "\n",
    "## Add display size for each ad\n",
    "def add_display_size(clicks):\n",
    "    clicks['display_size'] = clicks.groupby(['display_id'], sort=False)['ad_id'].transform('count')\n",
    "    return clicks\n",
    "\n",
    "## Lets not worry about these for now...\n",
    "def cleanup(clicks):\n",
    "    clicks.drop('geo_location', axis=1, inplace=True)\n",
    "    clicks.drop('timestamp', axis=1, inplace=True)\n",
    "    clicks.drop('campaign_id', axis=1, inplace=True)\n",
    "    clicks.drop('advertiser_id', axis=1, inplace=True)\n",
    "    clicks.drop('uuid', axis=1, inplace=True)\n",
    "    return clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing in the features analysed in FeatureAnalysis.pynb earlier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Pick the entity, topic and category with max confidence level for any document\n",
    "def confidence_max(topics):\n",
    "    topics_grouped = topics.groupby(['document_id'], sort=False).agg({'confidence_level':'max'})\n",
    "    topics_grouped = topics_grouped.reset_index()\n",
    "    topics_grouped = topics_grouped.rename(columns={'confidence_level':'confidence_max'})\n",
    "    topics = pd.merge(topics, topics_grouped, how='left', on=['document_id'])\n",
    "    del(topics_grouped)\n",
    "    topics = topics[topics['confidence_level'] == topics['confidence_max']]\n",
    "    topics.drop('confidence_level', axis=1, inplace=True)\n",
    "    topics.drop('confidence_max', axis=1, inplace=True)\n",
    "    topics = topics.drop_duplicates(subset=['document_id'])\n",
    "    return topics\n",
    "## Pick the topn topcis, entities and categories\n",
    "def most_frequent(topics, groupbykey, topn):\n",
    "    top_topics = topics.groupby(groupbykey, sort=False)['document_id'].count().sort_values(ascending=False).head(topn).index\n",
    "    return topics[topics[groupbykey].isin(top_topics)]\n",
    "## Create dummy variables\n",
    "def convert_to_dummies(topics, key):\n",
    "    topics = pd.concat([topics, pd.get_dummies(topics[key])], axis=1, join='inner')\n",
    "    topics.drop(key, axis=1, inplace=True)\n",
    "    #topics = topics.groupby(by='document_id', sort=False).agg(sum).reset_index() #Combine confidence level in one row\n",
    "    return topics\n",
    "## Add the category, topics and entity dummy variables as features\n",
    "def featurize_document_meta(clicks, topics, key, topn):\n",
    "    topics = convert_to_dummies(most_frequent(confidence_max(topics), key, topn), key).to_sparse(fill_value=0);\n",
    "    # Hydrate source document categories/topics/entities\n",
    "    clicks = pd.merge(clicks, topics, how = 'left', left_on = 'source_document_id', right_on = 'document_id')\n",
    "    clicks.drop('document_id_y', axis=1, inplace=True)\n",
    "    clicks.rename(columns={'document_id_x':'document_id'}, inplace=True)\n",
    "    # Hydrate destination document categories/topics/entities\n",
    "    clicks = pd.merge(clicks, topics, how = 'left', left_on = 'document_id', right_on = 'document_id')\n",
    "    clicks.fillna(0, inplace=True) #NaN treated as not belonging to any Category (unknown category)\n",
    "    return clicks  \n",
    "    \n",
    "def featurize(clicks):\n",
    "    categories = pd.read_csv('./data/documents_categories.csv',  dtype={\"document_id\": int, \"category_id\": int, \"confidence_level\": float})\n",
    "    #Create Category dummies\n",
    "    clicks = featurize_document_meta(clicks, categories, 'category_id', 5)\n",
    "    del(categories)\n",
    "    ## Ignoring Entity and Topics to avoid out-of-memory errors.\n",
    "    #Create Entity dummies\n",
    "    #entities = pd.read_csv('./data/documents_entities.csv',  dtype={\"document_id\": int, \"entity_id\": object, \"confidence_level\": float})\n",
    "    #clicks = featurize_document_meta(clicks, entities, 'entity_id', 5)\n",
    "    #del(entities)\n",
    "    #Create Topics dummies\n",
    "    #topics = pd.read_csv('./data/documents_topics.csv',  dtype={\"document_id\": int, \"topic_id\": int, \"confidence_level\": float})\n",
    "    #clicks = featurize_document_meta(clicks, topics, 'topic_id', 5)\n",
    "    #del(topics)\n",
    "    clicks.drop('source_document_id', axis=1, inplace=True)\n",
    "    clicks.drop('document_id', axis=1, inplace=True)\n",
    "    return clicks    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clicks_train = pd.read_csv('./data/clicks_train.csv',  dtype={\"display_id\": int, \"ad_id\": int, \"clicked\": int})\n",
    "if poor:\n",
    "    clicks_train = clicks_train.head(1001) #1002 is a different display id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clicks_train = add_documents_ids(clicks_train)\n",
    "gc.collect()\n",
    "clicks_train = add_reg_ctr(clicks_train)\n",
    "gc.collect()\n",
    "clicks_train = add_display_size(clicks_train)\n",
    "gc.collect()\n",
    "clicks_train.drop('ad_id', axis=1, inplace=True)\n",
    "clicks_train.drop('display_id', axis=1, inplace=True)\n",
    "\n",
    "clicks_train = featurize(clicks_train)\n",
    "clicks_train = clicks_train.to_sparse(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn import tree\n",
    "#model = tree.DecisionTreeClassifier(criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Choose the RandomForest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model= RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = clicks_train[clicks_train.columns.difference(['clicked']).values]\n",
    "Y = clicks_train['clicked'].to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1403_x</th>\n",
       "      <th>1403_y</th>\n",
       "      <th>1513_x</th>\n",
       "      <th>1513_y</th>\n",
       "      <th>1702_x</th>\n",
       "      <th>1702_y</th>\n",
       "      <th>1902_x</th>\n",
       "      <th>1902_y</th>\n",
       "      <th>1907_x</th>\n",
       "      <th>1907_y</th>\n",
       "      <th>display_size</th>\n",
       "      <th>platform</th>\n",
       "      <th>reg_ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.167133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.167133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.167133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.167133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.167133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1403_x  1403_y  1513_x  1513_y  1702_x  1702_y  1902_x  1902_y  1907_x  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   1907_y  display_size  platform   reg_ctr  \n",
       "0     0.0             6         3  0.167133  \n",
       "1     0.0             3         3  0.167133  \n",
       "2     0.0             4         1  0.167133  \n",
       "3     0.0             6         1  0.167133  \n",
       "4     0.0             4         1  0.167133  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Independent variables\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: clicked, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dependent variable\n",
    "Y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## GridSearch hyper-parameters tuning\n",
    "## I had to choose modest numbers else I would run out of memory or the search would never complete.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {   'n_estimators': [3], #[100, 1000], \n",
    "                 'min_samples_leaf': [0.10],\n",
    "                 'max_features' : [None],\n",
    "                 'criterion': ['gini', 'entropy'],\n",
    "                  'n_jobs' : [4]\n",
    "             }\n",
    "grid_clf = GridSearchCV(model, param_grid, cv=2)\n",
    "#Although Cross validation is not required with RandomForest cv parameter cannot be none or  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [3], 'max_features': [None], 'n_jobs': [4], 'criterion': ['gini', 'entropy'], 'min_samples_leaf': [0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_features': None,\n",
       " 'min_samples_leaf': 0.1,\n",
       " 'n_estimators': 3,\n",
       " 'n_jobs': 4}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80635461775069095"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose the best model that GridSearch found\n",
    "model = grid_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1337"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Don't need the training data after this point\n",
    "del(X)\n",
    "del(Y)\n",
    "del(clicks_train)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Read in test data\n",
    "clicks_test = pd.read_csv('./data/clicks_test.csv',  dtype={\"display_id\": int, \"ad_id\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Featurize it similar to training data\n",
    "clicks_test = add_documents_ids(clicks_test)\n",
    "clicks_test = add_reg_ctr(clicks_test)\n",
    "clicks_test = add_display_size(clicks_test).to_sparse(fill_value=0)\n",
    "clicks_test = featurize(clicks_test).to_sparse(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1403_x</th>\n",
       "      <th>1403_y</th>\n",
       "      <th>1513_x</th>\n",
       "      <th>1513_y</th>\n",
       "      <th>1702_x</th>\n",
       "      <th>1702_y</th>\n",
       "      <th>1902_x</th>\n",
       "      <th>1902_y</th>\n",
       "      <th>1907_x</th>\n",
       "      <th>1907_y</th>\n",
       "      <th>display_size</th>\n",
       "      <th>platform</th>\n",
       "      <th>reg_ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.065994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.065994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1403_x  1403_y  1513_x  1513_y  1702_x  1702_y  1902_x  1902_y  1907_x  \\\n",
       "0     0.0     0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   1907_y  display_size  platform   reg_ctr  \n",
       "0     0.0             6         3  0.065994  \n",
       "1     0.0             9         3  0.065994  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Indpendent variables\n",
    "clicks_test[clicks_test.columns.difference(['display_id', 'ad_id']).values].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Get probability of being clicked from model\n",
    "clicks_test['prob'] = model.predict_proba(clicks_test[clicks_test.columns.difference(['display_id', 'ad_id']).values])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## After this point we don't need the features\n",
    "clicks_test = clicks_test[['display_id','prob','ad_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Prepare to create submission\n",
    "clicks_test.sort_values(['display_id', 'prob'], inplace=True, ascending=[True, False])\n",
    "clicks_test.drop('prob', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Generate a submission\n",
    "\n",
    "## Lambda functions are super slow on large data set\n",
    "#clicks_test = clicks_test.groupby(by='display_id', sort=False).aggregate(lambda x: ' '.join([str(ff) for ff in x]))\n",
    "\n",
    "def f(df):\n",
    "         keys,values=df.values.T\n",
    "         ukeys,index=np.unique(keys,True)\n",
    "         arrays=np.split(values,index[1:])\n",
    "         df2=pd.DataFrame({'display_id':ukeys,'ad_id':[' '.join([str(ff) for ff in a]) for a in arrays]})\n",
    "         return df2\n",
    "clicks_test = f(clicks_test)[['display_id','ad_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Upload this file to Kaggle leaderboard\n",
    "clicks_test.to_csv('submission_rf_fd.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
