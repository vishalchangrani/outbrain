{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Toggle based on hardware - if low memory laptop set to True else False\n",
    "poor = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(It was earlier observed that Topics of some documents are not known, Cateogires of some documents are not known, Entities of some documents are not known\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#documents_meta = pd.read_csv('./data/documents_meta.csv',  dtype={\"document_id\": int, \"source_id\": object, \"publisher_id\": object, \"publish_time\": object})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source Id, Publisher Id and Publish time of all documents <b>are</b> known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Init\n",
    "events_df = pd.read_csv('./data/events.csv',  dtype={\"display_id\": int, \"uuid\": str, \"document_id\": int, \"timestamp\": int, \"platform\": str, \"geo_location\": str})\n",
    "categories = pd.read_csv('./data/documents_categories.csv',  dtype={\"document_id\": int, \"category_id\": int, \"confidence_level\": float})\n",
    "\n",
    "clicks_train = pd.read_csv('./data/clicks_train.csv',  dtype={\"display_id\": int, \"ad_id\": int, \"clicked\": int})\n",
    "if poor:\n",
    "    clicks_train = clicks_train.head(1001) #1002 is a different display id.\n",
    "clicks_test = pd.read_csv('./data/clicks_test.csv',  dtype={\"display_id\": int, \"ad_id\": int})\n",
    "\n",
    "clicks_train = pd.merge(clicks_train, events_df, on='display_id')\n",
    "clicks_test  = pd.merge(clicks_test, events_df, on='display_id')\n",
    "\n",
    "del(events_df) # save memory\n",
    "\n",
    "## Add target doucment id info from promoted content\n",
    "clicks_train = clicks_train.rename(index=str, columns={\"document_id\": \"source_document_id\"})\n",
    "clicks_test = clicks_test.rename(index=str, columns={\"document_id\": \"source_document_id\"})\n",
    "promoted_content = pd.read_csv('./data/promoted_content.csv',  dtype={\"ad_id\": int, \"document_id\": int, \"campaign_id\": object, \"advertiser_id\": object})\n",
    "clicks_train = pd.merge(clicks_train, promoted_content, on='ad_id')\n",
    "clicks_test = pd.merge(clicks_test, promoted_content, on='ad_id')\n",
    "del(promoted_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets not worry about these for now\n",
    "def cleanup(clicks):\n",
    "    clicks.drop('geo_location', axis=1, inplace=True)\n",
    "    clicks.drop('platform', axis=1, inplace=True)\n",
    "    clicks.drop('timestamp', axis=1, inplace=True)\n",
    "    clicks.drop('campaign_id', axis=1, inplace=True)\n",
    "    clicks.drop('advertiser_id', axis=1, inplace=True)\n",
    "    clicks.drop('uuid', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanup(clicks_test)\n",
    "cleanup(clicks_train)\n",
    "clicks_train.drop('ad_id', axis=1, inplace=True)\n",
    "clicks_train.drop('display_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets consider <b>Category</b> as our first feature (each Category as a unique feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def confidence_max(topics):\n",
    "    topics_grouped = topics.groupby(['document_id'], sort=False).agg({'confidence_level':'max'})\n",
    "    topics_grouped = topics_grouped.reset_index()\n",
    "    topics_grouped = topics_grouped.rename(columns={'confidence_level':'confidence_max'})\n",
    "    topics_grouped = topics_grouped.drop_duplicates(subset=['document_id'])\n",
    "    topics = pd.merge(topics, topics_grouped, how='left', on=['document_id'])\n",
    "    topics_grouped = None\n",
    "    topics = topics[topics['confidence_level'] == topics['confidence_max']]\n",
    "    topics.drop('confidence_level', axis=1, inplace=True)\n",
    "    topics.drop('confidence_max', axis=1, inplace=True)\n",
    "    topics = topics.drop_duplicates(subset=['document_id'])\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Crate Category dummies\n",
    "categories = confidence_max(categories)\n",
    "category_dummies = pd.get_dummies(categories['category_id'])\n",
    "categories.drop('category_id', axis=1, inplace=True)\n",
    "categories = pd.concat([categories, category_dummies], axis=1, join='inner')\n",
    "del(category_dummies)\n",
    "categories = categories.groupby(by='document_id', sort=False).agg(sum).reset_index() #Combine confidence level in one row\n",
    "categories = categories.to_sparse(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hydrate source document categories\n",
    "clicks_train = pd.merge(clicks_train, categories, how = 'left', left_on = 'source_document_id', right_on = 'document_id')\n",
    "clicks_test =  pd.merge(clicks_test,  categories, how = 'left', left_on = 'source_document_id', right_on = 'document_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clicks_train.drop('document_id_y', axis=1, inplace=True)\n",
    "clicks_train.rename(columns={'document_id_x':'document_id'}, inplace=True)\n",
    "clicks_test.drop('document_id_y', axis=1, inplace=True)\n",
    "clicks_test.rename(columns={'document_id_x':'document_id'}, inplace=True)\n",
    "clicks_test.drop('source_document_id', axis=1, inplace=True)\n",
    "clicks_train.drop('source_document_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hydrate destination document categories\n",
    "clicks_train = pd.merge(clicks_train, categories, how = 'left', left_on = 'document_id', right_on = 'document_id')\n",
    "clicks_test  = pd.merge(clicks_test, categories, how = 'left', left_on = 'document_id', right_on = 'document_id')\n",
    "clicks_train.drop('document_id', axis=1, inplace=True)\n",
    "clicks_test.drop('document_id', axis=1, inplace=True)\n",
    "clicks_train.fillna(0, inplace=True) #NaN treated as not belonging to any Category (unknown category)\n",
    "clicks_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "Y = clicks_train['clicked']\n",
    "\n",
    "clicks_train.drop('clicked', axis=1, inplace=True)\n",
    "\n",
    "model.fit(clicks_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.score(clicks_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clicks_test['prob'] = model.predict_proba(clicks_test.columns.difference(['display_id', 'ad_id']))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clicks_test.sort_values(['display_id', 'probs'], inplace=True, ascending=[True, False])\n",
    "clicks_test.drop('probs', axis=1, inplace=True)\n",
    "clicks_test = clicks_test.groupby(by='display_id', sort=False).aggregate(lambda x: ' '.join([str(ff) for ff in x]))\n",
    "clicks_test.to_csv('submission.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " = predicted\n",
    "\n",
    "probs = model.predict_proba(clicks_test)[:,1]\n",
    "\n",
    "org_train['probs'] = probs\n",
    "\n",
    "org_train.sort_values(['display_id', 'probs'], inplace=True, ascending=[True, False] )\n",
    "\n",
    "Y_ads = org_train[ org_train.clicked == 1 ].ad_id.values.reshape(-1,1)\n",
    "\n",
    "P_ads = org_train.groupby(by='display_id', sort=False).ad_id.apply( lambda x: x.values ).values\n",
    "\n",
    "from ml_metrics import mapk\n",
    "\n",
    "score = mapk( Y_ads, P_ads, 12 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"MAP: %.12f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = org_train.groupby(['display_id']).first()\n",
    "\n",
    "TP = len(result[result['clicked'] == 1])\n",
    "\n",
    "FP = len(result[result['clicked'] != 1])\n",
    "\n",
    "print \"Simple Precision = %.2f\"%(TP / float(TP + FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
