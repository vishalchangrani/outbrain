{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import gc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Toggle based on hardware - if low memory laptop set to True else False\n",
    "poor = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(It was earlier observed that Topics of some documents are not known, Cateogires of some documents are not known, Entities of some documents are not known\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_meta = pd.read_csv('./data/documents_meta.csv',  dtype={\"document_id\": int, \"source_id\": object, \"publisher_id\": object, \"publish_time\": object})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source Id, Publisher Id and Publish time of all documents <b>are</b> known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Init\n",
    "def add_documents_ids(clicks):\n",
    "    events_df = pd.read_csv('./data/events.csv',  dtype={\"display_id\": int, \"uuid\": str, \"document_id\": int, \"timestamp\": int, \"platform\": str, \"geo_location\": str})\n",
    "    events_df = events_df[events_df.platform != '\\\\N']\n",
    "    events_df.platform = events_df.platform.astype(int)\n",
    "    clicks    = pd.merge(clicks, events_df, on='display_id')\n",
    "    del(events_df) # save memory\n",
    "    ## Add target doucment id info from promoted content\n",
    "    clicks = clicks.rename(index=str, columns={\"document_id\": \"source_document_id\"})\n",
    "    promoted_content = pd.read_csv('./data/promoted_content.csv',  dtype={\"ad_id\": int, \"document_id\": int, \"campaign_id\": object, \"advertiser_id\": object})\n",
    "    clicks = pd.merge(clicks, promoted_content, on='ad_id')\n",
    "    del(promoted_content)\n",
    "    return cleanup(clicks)\n",
    "\n",
    "def add_reg_ctr(clicks):\n",
    "    reg_ctr = pd.read_csv('./reg_ctr.csv',dtype={\"ad_id\":int, \"reg_ctr\":float})\n",
    "    clicks = pd.merge(clicks, reg_ctr, how = 'left', on = 'ad_id')\n",
    "    clicks['reg_ctr'].fillna(0, inplace=True)\n",
    "    del(reg_ctr)\n",
    "    return clicks\n",
    "\n",
    "def add_display_size(clicks):\n",
    "    clicks['display_size'] = clicks.groupby(['display_id'], sort=False)['ad_id'].transform('count')\n",
    "    return clicks\n",
    "\n",
    "    #Lets not worry about these for now\n",
    "def cleanup(clicks):\n",
    "    clicks.drop('geo_location', axis=1, inplace=True)\n",
    "    clicks.drop('timestamp', axis=1, inplace=True)\n",
    "    clicks.drop('campaign_id', axis=1, inplace=True)\n",
    "    clicks.drop('advertiser_id', axis=1, inplace=True)\n",
    "    clicks.drop('uuid', axis=1, inplace=True)\n",
    "    return clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing in the features analysed in FeatureAnalysis.pynb earlier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def confidence_max(topics):\n",
    "    topics_grouped = topics.groupby(['document_id'], sort=False).agg({'confidence_level':'max'})\n",
    "    topics_grouped = topics_grouped.reset_index()\n",
    "    topics_grouped = topics_grouped.rename(columns={'confidence_level':'confidence_max'})\n",
    "    topics = pd.merge(topics, topics_grouped, how='left', on=['document_id'])\n",
    "    del(topics_grouped)\n",
    "    topics = topics[topics['confidence_level'] == topics['confidence_max']]\n",
    "    topics.drop('confidence_level', axis=1, inplace=True)\n",
    "    topics.drop('confidence_max', axis=1, inplace=True)\n",
    "    topics = topics.drop_duplicates(subset=['document_id'])\n",
    "    return topics\n",
    "def most_frequent(topics, groupbykey, topn):\n",
    "    top_topics = topics.groupby(groupbykey, sort=False)['document_id'].count().sort_values(ascending=False).head(topn).index\n",
    "    return topics[topics[groupbykey].isin(top_topics)]\n",
    "def convert_to_dummies(topics, key):\n",
    "    topics = pd.concat([topics, pd.get_dummies(topics[key])], axis=1, join='inner')\n",
    "    topics.drop(key, axis=1, inplace=True)\n",
    "    #topics = topics.groupby(by='document_id', sort=False).agg(sum).reset_index() #Combine confidence level in one row\n",
    "    return topics\n",
    "def featurize_document_meta(clicks, topics, key, topn):\n",
    "    topics = convert_to_dummies(most_frequent(confidence_max(topics), key, topn), key).to_sparse(fill_value=0);\n",
    "    # Hydrate source document categories/topics/entities\n",
    "    clicks = pd.merge(clicks, topics, how = 'left', left_on = 'source_document_id', right_on = 'document_id')\n",
    "    clicks.drop('document_id_y', axis=1, inplace=True)\n",
    "    clicks.rename(columns={'document_id_x':'document_id'}, inplace=True)\n",
    "    # Hydrate destination document categories/topics/entities\n",
    "    clicks = pd.merge(clicks, topics, how = 'left', left_on = 'document_id', right_on = 'document_id')\n",
    "    clicks.fillna(0, inplace=True) #NaN treated as not belonging to any Category (unknown category)\n",
    "    return clicks  \n",
    "    \n",
    "def featurize(clicks):\n",
    "    categories = pd.read_csv('./data/documents_categories.csv',  dtype={\"document_id\": int, \"category_id\": int, \"confidence_level\": float})\n",
    "    #Create Category dummies\n",
    "    clicks = featurize_document_meta(clicks, categories, 'category_id', 5)\n",
    "    del(categories)\n",
    "    #Create Entity dummies\n",
    "    entities = pd.read_csv('./data/documents_entities.csv',  dtype={\"document_id\": int, \"entity_id\": object, \"confidence_level\": float})\n",
    "    clicks = featurize_document_meta(clicks, entities, 'entity_id', 5)\n",
    "    del(entities)\n",
    "    #Create Topics dummies\n",
    "    topics = pd.read_csv('./data/documents_topics.csv',  dtype={\"document_id\": int, \"topic_id\": int, \"confidence_level\": float})\n",
    "    clicks = featurize_document_meta(clicks, topics, 'topic_id', 5)\n",
    "    del(topics)\n",
    "    clicks.drop('source_document_id', axis=1, inplace=True)\n",
    "    clicks.drop('document_id', axis=1, inplace=True)\n",
    "    return clicks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clicks_train = pd.read_csv('./data/clicks_train.csv',  dtype={\"display_id\": int, \"ad_id\": int, \"clicked\": int})\n",
    "if poor:\n",
    "    clicks_train = clicks_train.head(1001) #1002 is a different display id.\n",
    "clicks_train = add_documents_ids(clicks_train)\n",
    "\n",
    "clicks_train = add_reg_ctr(clicks_train)\n",
    "clicks_train = add_display_size(clicks_train)\n",
    "\n",
    "#clicks_train.drop('ad_id', axis=1, inplace=True)\n",
    "#clicks_train.drop('display_id', axis=1, inplace=True)\n",
    "\n",
    "#clicks_train = featurize(clicks_train)\n",
    "clicks_train = clicks_train.to_sparse(fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clicks_train.drop('ad_id', axis=1, inplace=True)\n",
    "clicks_train.drop('display_id', axis=1, inplace=True)\n",
    "clicks_train.drop('source_document_id', axis=1, inplace=True)\n",
    "clicks_train.drop('document_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn import tree\n",
    "#model = tree.DecisionTreeClassifier(criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model= RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = clicks_train[clicks_train.columns.difference(['clicked']).values]\n",
    "Y = clicks_train['clicked'].to_dense()\n",
    "#model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {   'n_estimators': [3], #[100, 1000], \n",
    "                 'min_samples_leaf': [0.20],\n",
    "                 'max_features' : [None],\n",
    "                 'criterion': ['gini', 'entropy'],\n",
    "                  'n_jobs' : [4]\n",
    "             }\n",
    "grid_clf = GridSearchCV(model, param_grid, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [3], 'max_features': [None], 'n_jobs': [4], 'criterion': ['gini', 'entropy'], 'min_samples_leaf': [0.2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_features': None,\n",
       " 'min_samples_leaf': 0.2,\n",
       " 'n_estimators': 3,\n",
       " 'n_jobs': 4}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80619380619380621"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose the best model that GridSearch found\n",
    "model = grid_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "905"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(clicks_train)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clicks_test = pd.read_csv('./data/clicks_test.csv',  dtype={\"display_id\": int, \"ad_id\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clicks_test = add_documents_ids(clicks_test)\n",
    "clicks_test = add_reg_ctr(clicks_test)\n",
    "clicks_test = add_display_size(clicks_test).to_sparse(fill_value=0)\n",
    "#clicks_test = featurize(clicks_test).to_sparse(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_id</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>reg_ctr</th>\n",
       "      <th>display_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16874594</td>\n",
       "      <td>66758</td>\n",
       "      <td>3</td>\n",
       "      <td>0.065994</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16874737</td>\n",
       "      <td>66758</td>\n",
       "      <td>3</td>\n",
       "      <td>0.065994</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   display_id  ad_id  platform   reg_ctr  display_size\n",
       "0    16874594  66758         3  0.065994             6\n",
       "1    16874737  66758         3  0.065994             9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicks_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clicks_test.drop('source_document_id', axis=1, inplace=True)\n",
    "clicks_test.drop('document_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clicks_test['prob'] = model.predict_proba(clicks_test[clicks_test.columns.difference(['display_id', 'ad_id']).values])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clicks_test = clicks_test[['display_id','prob','ad_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clicks_test.sort_values(['display_id', 'prob'], inplace=True, ascending=[True, False])\n",
    "clicks_test.drop('prob', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clicks_test = clicks_test.groupby(by='display_id', sort=False).aggregate(lambda x: ' '.join([str(ff) for ff in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(df):\n",
    "         keys,values=df.values.T\n",
    "         ukeys,index=np.unique(keys,True)\n",
    "         arrays=np.split(values,index[1:])\n",
    "         df2=pd.DataFrame({'display_id':ukeys,'ad_id':[' '.join([str(ff) for ff in a]) for a in arrays]})\n",
    "         return df2\n",
    "clicks_test = f(clicks_test)[['display_id','ad_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clicks_test.to_csv('submission_rf.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " = predicted\n",
    "\n",
    "probs = model.predict_proba(clicks_test)[:,1]\n",
    "\n",
    "org_train['probs'] = probs\n",
    "\n",
    "org_train.sort_values(['display_id', 'probs'], inplace=True, ascending=[True, False] )\n",
    "\n",
    "Y_ads = org_train[ org_train.clicked == 1 ].ad_id.values.reshape(-1,1)\n",
    "\n",
    "P_ads = org_train.groupby(by='display_id', sort=False).ad_id.apply( lambda x: x.values ).values\n",
    "\n",
    "from ml_metrics import mapk\n",
    "\n",
    "score = mapk( Y_ads, P_ads, 12 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"MAP: %.12f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = org_train.groupby(['display_id']).first()\n",
    "\n",
    "TP = len(result[result['clicked'] == 1])\n",
    "\n",
    "FP = len(result[result['clicked'] != 1])\n",
    "\n",
    "print \"Simple Precision = %.2f\"%(TP / float(TP + FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
