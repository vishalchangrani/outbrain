{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Toggle based on hardware - if low memory laptop set to True else False\n",
    "poor = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(It was earlier observed that Topics of some documents are not known, Cateogires of some documents are not known, Entities of some documents are not known\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_meta = pd.read_csv('./data/documents_meta.csv',  dtype={\"document_id\": int, \"source_id\": object, \"publisher_id\": object, \"publish_time\": object})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source Id, Publisher Id and Publish time of all documents <b>are</b> known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Init\n",
    "events_df = pd.read_csv('./data/events.csv',  dtype={\"display_id\": int, \"uuid\": str, \"document_id\": int, \"timestamp\": int, \"platform\": str, \"geo_location\": str})\n",
    "\n",
    "clicks_train = pd.read_csv('./data/clicks_train.csv',  dtype={\"display_id\": int, \"ad_id\": int, \"clicked\": int})\n",
    "if poor:\n",
    "    clicks_train = clicks_train.head(1001) #1002 is a different display id.\n",
    "clicks_test = pd.read_csv('./data/clicks_test.csv',  dtype={\"display_id\": int, \"ad_id\": int})\n",
    "\n",
    "clicks_train = pd.merge(clicks_train, events_df, on='display_id')\n",
    "clicks_test  = pd.merge(clicks_test, events_df, on='display_id')\n",
    "\n",
    "del(events_df) # save memory\n",
    "\n",
    "## Add target doucment id info from promoted content\n",
    "clicks_train = clicks_train.rename(index=str, columns={\"document_id\": \"source_document_id\"})\n",
    "clicks_test = clicks_test.rename(index=str, columns={\"document_id\": \"source_document_id\"})\n",
    "promoted_content = pd.read_csv('./data/promoted_content.csv',  dtype={\"ad_id\": int, \"document_id\": int, \"campaign_id\": object, \"advertiser_id\": object})\n",
    "clicks_train = pd.merge(clicks_train, promoted_content, on='ad_id')\n",
    "clicks_test = pd.merge(clicks_test, promoted_content, on='ad_id')\n",
    "del(promoted_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets not worry about these for now\n",
    "def cleanup(clicks):\n",
    "    clicks.drop('geo_location', axis=1, inplace=True)\n",
    "    clicks.drop('platform', axis=1, inplace=True)\n",
    "    clicks.drop('timestamp', axis=1, inplace=True)\n",
    "    clicks.drop('campaign_id', axis=1, inplace=True)\n",
    "    clicks.drop('advertiser_id', axis=1, inplace=True)\n",
    "    clicks.drop('uuid', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanup(clicks_test)\n",
    "cleanup(clicks_train)\n",
    "clicks_train.drop('ad_id', axis=1, inplace=True)\n",
    "clicks_train.drop('display_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing in the features analysed in FeatureAnalysis.pynb earlier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def confidence_max(topics):\n",
    "    topics_grouped = topics.groupby(['document_id'], sort=False).agg({'confidence_level':'max'})\n",
    "    topics_grouped = topics_grouped.reset_index()\n",
    "    topics_grouped = topics_grouped.rename(columns={'confidence_level':'confidence_max'})\n",
    "    topics = pd.merge(topics, topics_grouped, how='left', on=['document_id'])\n",
    "    del(topics_grouped)\n",
    "    topics = topics[topics['confidence_level'] == topics['confidence_max']]\n",
    "    topics.drop('confidence_level', axis=1, inplace=True)\n",
    "    topics.drop('confidence_max', axis=1, inplace=True)\n",
    "    topics = topics.drop_duplicates(subset=['document_id'])\n",
    "    return topics\n",
    "def most_frequent(topics, groupbykey, topn):\n",
    "    top_topics = topics.groupby(groupbykey, sort=False)['document_id'].count().sort_values(ascending=False).head(topn).index\n",
    "    return topics[topics[groupbykey].isin(top_topics)]\n",
    "def convert_to_dummies(topics, key):\n",
    "    topics = pd.concat([topics, pd.get_dummies(topics[key])], axis=1, join='inner')\n",
    "    topics.drop(key, axis=1, inplace=True)\n",
    "    #topics = topics.groupby(by='document_id', sort=False).agg(sum).reset_index() #Combine confidence level in one row\n",
    "    return topics\n",
    "def featurize(topics, key, topn):\n",
    "    return convert_to_dummies(most_frequent(confidence_max(topics), key, topn), key).to_sparse(fill_value=0);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = pd.read_csv('./data/documents_categories.csv',  dtype={\"document_id\": int, \"category_id\": int, \"confidence_level\": float})\n",
    "\n",
    "#Crate Category dummies\n",
    "categories = featurize(categories, 'category_id', 5)\n",
    "\n",
    "# Hydrate source document categories\n",
    "clicks_train = pd.merge(clicks_train, categories, how = 'left', left_on = 'source_document_id', right_on = 'document_id')\n",
    "clicks_test =  pd.merge(clicks_test,  categories, how = 'left', left_on = 'source_document_id', right_on = 'document_id')\n",
    "\n",
    "clicks_train.drop('document_id_y', axis=1, inplace=True)\n",
    "clicks_train.rename(columns={'document_id_x':'document_id'}, inplace=True)\n",
    "clicks_test.drop('document_id_y', axis=1, inplace=True)\n",
    "clicks_test.rename(columns={'document_id_x':'document_id'}, inplace=True)\n",
    "\n",
    "\n",
    "# Hydrate destination document categories\n",
    "clicks_train = pd.merge(clicks_train, categories, how = 'left', left_on = 'document_id', right_on = 'document_id')\n",
    "clicks_test  = pd.merge(clicks_test, categories, how = 'left', left_on = 'document_id', right_on = 'document_id')\n",
    "\n",
    "clicks_train.fillna(0, inplace=True) #NaN treated as not belonging to any Category (unknown category)\n",
    "clicks_test.fillna(0, inplace=True)\n",
    "\n",
    "del(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities = pd.read_csv('./data/documents_entities.csv',  dtype={\"document_id\": int, \"entity_id\": object, \"confidence_level\": float})\n",
    "\n",
    "#Crate Entity dummies\n",
    "entities = featurize(entities, 'entity_id', 5)\n",
    "\n",
    "# Hydrate source document categories\n",
    "clicks_train = pd.merge(clicks_train, entities, how = 'left', left_on = 'source_document_id', right_on = 'document_id')\n",
    "clicks_test =  pd.merge(clicks_test,  entities, how = 'left', left_on = 'source_document_id', right_on = 'document_id')\n",
    "\n",
    "clicks_train.drop('document_id_y', axis=1, inplace=True)\n",
    "clicks_train.rename(columns={'document_id_x':'document_id'}, inplace=True)\n",
    "clicks_test.drop('document_id_y', axis=1, inplace=True)\n",
    "clicks_test.rename(columns={'document_id_x':'document_id'}, inplace=True)\n",
    "\n",
    "# Hydrate destination document categories\n",
    "clicks_train = pd.merge(clicks_train, entities, how = 'left', left_on = 'document_id', right_on = 'document_id')\n",
    "clicks_test  = pd.merge(clicks_test, entities, how = 'left', left_on = 'document_id', right_on = 'document_id')\n",
    "clicks_train.fillna(0, inplace=True) #NaN treated as not belonging to any Category (unknown category)\n",
    "clicks_test.fillna(0, inplace=True)\n",
    "\n",
    "del(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = pd.read_csv('./data/documents_topics.csv',  dtype={\"document_id\": int, \"topic_id\": int, \"confidence_level\": float})\n",
    "\n",
    "#Crate Title dummies\n",
    "topics = featurize(topics, 'topic_id', 5)\n",
    "\n",
    "# Hydrate source document categories\n",
    "clicks_train = pd.merge(clicks_train, topics, how = 'left', left_on = 'source_document_id', right_on = 'document_id')\n",
    "clicks_test =  pd.merge(clicks_test,  topics, how = 'left', left_on = 'source_document_id', right_on = 'document_id')\n",
    "\n",
    "clicks_train.drop('document_id_y', axis=1, inplace=True)\n",
    "clicks_train.rename(columns={'document_id_x':'document_id'}, inplace=True)\n",
    "clicks_test.drop('document_id_y', axis=1, inplace=True)\n",
    "clicks_test.rename(columns={'document_id_x':'document_id'}, inplace=True)\n",
    "\n",
    "# Hydrate destination document categories\n",
    "clicks_train = pd.merge(clicks_train, topics, how = 'left', left_on = 'document_id', right_on = 'document_id')\n",
    "clicks_test  = pd.merge(clicks_test, topics, how = 'left', left_on = 'document_id', right_on = 'document_id')\n",
    "clicks_train.fillna(0, inplace=True) #NaN treated as not belonging to any Category (unknown category)\n",
    "clicks_test.fillna(0, inplace=True)\n",
    "\n",
    "del(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clicks_test.drop('source_document_id', axis=1, inplace=True)\n",
    "clicks_train.drop('source_document_id', axis=1, inplace=True)\n",
    "clicks_train.drop('document_id', axis=1, inplace=True)\n",
    "clicks_test.drop('document_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "Y = clicks_train['clicked']\n",
    "\n",
    "clicks_train.drop('clicked', axis=1, inplace=True)\n",
    "\n",
    "model.fit(clicks_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81518481518481523"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(clicks_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clicks_test[clicks_test.columns.difference(['display_id', 'ad_id'])].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clicks_test['prob'] = model.predict_proba(clicks_test.columns.difference(['display_id', 'ad_id']))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clicks_test.sort_values(['display_id', 'probs'], inplace=True, ascending=[True, False])\n",
    "clicks_test.drop('probs', axis=1, inplace=True)\n",
    "clicks_test = clicks_test.groupby(by='display_id', sort=False).aggregate(lambda x: ' '.join([str(ff) for ff in x]))\n",
    "clicks_test.to_csv('submission.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " = predicted\n",
    "\n",
    "probs = model.predict_proba(clicks_test)[:,1]\n",
    "\n",
    "org_train['probs'] = probs\n",
    "\n",
    "org_train.sort_values(['display_id', 'probs'], inplace=True, ascending=[True, False] )\n",
    "\n",
    "Y_ads = org_train[ org_train.clicked == 1 ].ad_id.values.reshape(-1,1)\n",
    "\n",
    "P_ads = org_train.groupby(by='display_id', sort=False).ad_id.apply( lambda x: x.values ).values\n",
    "\n",
    "from ml_metrics import mapk\n",
    "\n",
    "score = mapk( Y_ads, P_ads, 12 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"MAP: %.12f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = org_train.groupby(['display_id']).first()\n",
    "\n",
    "TP = len(result[result['clicked'] == 1])\n",
    "\n",
    "FP = len(result[result['clicked'] != 1])\n",
    "\n",
    "print \"Simple Precision = %.2f\"%(TP / float(TP + FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
